"""LoadData CSV validation framework.

This module provides a simplified framework for validating LoadData CSV files
generated by different pipeline steps in the StarryNight workflow.

"""

from dataclasses import dataclass
from typing import Any

import pandas as pd


@dataclass
class ComparisonReport:
    missing_reference_columns: list[str]
    extra_generated_columns: list[str]
    reference_row_count: int
    generated_row_count: int
    extra_rows_in_generated: int
    missing_rows_in_generated: int
    missing_values: dict[str, set[Any]]
    errors: list[str]
    warnings: list[str]

    def format_errors(self):
        """Return formatted error messages with numbering."""
        if not self.errors:
            return None
        return "\n".join(
            f"Error {i + 1}: {error}" for i, error in enumerate(self.errors)
        )

    def format_warnings(self):
        """Return formatted warning messages with numbering."""
        if not self.warnings:
            return None
        return "\n".join(
            f"Warning {i + 1}: {warning}"
            for i, warning in enumerate(self.warnings)
        )


def compare_csvs(  # noqa: C901
    reference_csv_path: str,
    generated_csv_path: str,
    key_columns: list[str] | None = None,
    skip_column_substrings: list[str] | None = None,
    default_key_columns: list[str] = [
        "Metadata_Plate",
        "Metadata_Well",
        "Metadata_Site",
        "Metadata_Cycle",
    ],
) -> ComparisonReport:
    """Compare a generated CSV against a reference CSV and return a structured report.

    Parameters
    ----------
    reference_csv_path : str
        Path to the reference CSV file.
    generated_csv_path : str
        Path to the generated CSV file.
    key_columns : Optional[list[str]]
        List of column names that define a unique row. If None, defaults to
        default_key_columns filtered by those actually present in the reference.
    skip_column_substrings : Optional[list[str]]
        Columns containing any of these substrings are skipped for unique-value coverage checks.
    default_key_columns : Optional[list[str]]
        The default columns to use for row identification if key_columns is not explicitly provided.

    Returns
    -------
    ComparisonReport
        An object containing lists of errors and warnings plus metrics.

    """
    # Load CSVs
    ref = pd.read_csv(reference_csv_path)
    gen = pd.read_csv(generated_csv_path)

    # Determine key columns
    if key_columns is None:
        key_columns = [c for c in default_key_columns if c in ref.columns]

    skip_subs = skip_column_substrings or []

    # Column-level checks
    ref_cols = set(ref.columns)
    gen_cols = set(gen.columns)

    missing_reference_columns = sorted(ref_cols - gen_cols)
    extra_generated_columns = sorted(gen_cols - ref_cols)

    # Row counts
    reference_row_count = len(ref)
    generated_row_count = len(gen)

    # Row-key sets for comparison
    if key_columns:
        # Sort by reference column order
        ref_sorted = ref.sort_values(by=key_columns, na_position="first")
        gen_sorted = gen.sort_values(by=key_columns, na_position="first")

        # Build sets of key tuples (fill NA to ensure hashable)
        ref_keys = set(
            tuple(row)
            for row in ref_sorted[key_columns]
            .fillna("")
            .itertuples(index=False, name=None)
        )
        gen_keys = set(
            tuple(row)
            for row in gen_sorted[key_columns]
            .fillna("")
            .itertuples(index=False, name=None)
        )

        extra_rows_in_generated = len(gen_keys - ref_keys)
        missing_rows_in_generated = len(ref_keys - gen_keys)
    else:
        # No key columns: compare counts only
        extra_rows_in_generated = max(
            0, generated_row_count - reference_row_count
        )
        missing_rows_in_generated = max(
            0, reference_row_count - generated_row_count
        )

    # Unique-value coverage
    common_cols = [c for c in ref.columns if c in gen.columns]
    missing_values: dict[str, set[Any]] = {}
    for col in common_cols:
        if any(sub in col for sub in skip_subs):
            continue
        ref_vals = set(ref[col].dropna().unique())
        gen_vals = set(gen[col].dropna().unique())
        missing = ref_vals - gen_vals
        if missing:
            missing_values[col] = missing

    # Assemble human-readable messages
    errors: list[str] = []
    warnings: list[str] = []

    for col in missing_reference_columns:
        errors.append(f"Missing reference column in generated: '{col}'")
    for col in extra_generated_columns:
        warnings.append(f"Extra column in generated not in reference: '{col}'")

    if missing_rows_in_generated > 0:
        errors.append(
            f"Missing {missing_rows_in_generated} rows in generated relative to reference"
        )
    if extra_rows_in_generated > 0:
        warnings.append(
            f"{extra_rows_in_generated} extra rows in generated relative to reference"
        )

    for col, vals in missing_values.items():
        sample = sorted(list(vals))[:10]
        more = "..." if len(vals) > 10 else ""
        errors.append(f"Column '{col}' missing reference values {sample}{more}")

    # Build and return report
    report = ComparisonReport(
        missing_reference_columns=missing_reference_columns,
        extra_generated_columns=extra_generated_columns,
        reference_row_count=reference_row_count,
        generated_row_count=generated_row_count,
        extra_rows_in_generated=extra_rows_in_generated,
        missing_rows_in_generated=missing_rows_in_generated,
        missing_values=missing_values,
        errors=errors,
        warnings=warnings,
    )
    return report
