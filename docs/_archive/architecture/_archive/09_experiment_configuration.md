# StarryNight Experiment Configuration

## Overview

Experiment configuration in StarryNight provides a systematic way to manage experiment-specific parameters, infer settings from data, and configure modules. It bridges the gap between user-provided parameters and the detailed configuration needed for pipeline execution.

## Purpose

The experiment configuration layer serves several key purposes:

1. **Parameter Management** - Collecting essential experiment parameters
2. **Parameter Inference** - Determining settings automatically from data
3. **Standardization** - Providing consistent configuration across modules
4. **Extensibility** - Supporting different experiment types
5. **Module Configuration** - Simplifying the configuration of pipeline modules

As explained in the transcript:

> "...once we are done with indexing and inventory and indexing, then we move to like, you know what specific experiment I'm actually doing, right? So based on that, we we prepare certain conflicts."

## Experiment Classes

Experiments are implemented as Python classes that inherit from a base experiment class:

```python
class PCPGenericExperiment(ExperimentBase):
    """
    Experiment configuration for generic Plate Cell Painting.
    """
    # Implementation...
```

The transcript examines the `PCPGenericExperiment` class as an example.

## From Index Method

A critical method in experiment classes is `from_index`, which initializes the experiment from index data:

> "There is a function called from index on your experimental side of things... So you give it your index path and your experiment, this initial config, which cannot be guessed, and then it will guess everything else that's required in your, in your, you know, in a downstream pipeline..."

This method takes two main parameters:

1. **Index Path** - Path to the index file generated by indexing
2. **Initial Config** - User-provided parameters that cannot be inferred

```python
@classmethod
def from_index(cls, index_path: AnyPath, init_config: Dict[str, Any]) -> "PCPGenericExperiment":
    """
    Create experiment configuration from index and initial config.

    Parameters
    ----------
    index_path : AnyPath
        Path to the index file
    init_config : Dict[str, Any]
        Initial configuration parameters

    Returns
    -------
    PCPGenericExperiment
        Configured experiment instance
    """
    # Implementation...
```

## Initial Configuration

The initial configuration includes parameters that cannot be inferred from data:

```python
pcp_init_config = {
    "nuclear_channel": "DAPI",
    "cell_channel": "CellMask",
    "mito_channel": "MitoTracker",
    "barcode_csv_path": "/path/to/barcodes.csv",
    "image_overlap_percentage": 10
}
```

These parameters are experiment-specific and must be provided by the user.

## Parameter Inference

A key feature of experiment classes is their ability to infer parameters from data:

> "It will extract what a data set ID is. It will create a data frame for all the CP images, for SPS images, and then calculate how many images are per Well, for the cell painting things right? Because it knows it has the inventory. It can do queries against the inventory and then figure out, like for each well, how many images are there, right?"

Examples of inferred parameters:

1. **Images per Well** - Calculated from inventory data
2. **Channel Count** - Determined from image metadata
3. **Channel List** - Extracted from available images
4. **Dataset Structure** - Inferred from file organization

This inference reduces the manual configuration burden on users.

## Implementation Example

Here's a simplified example of parameter inference in the `from_index` method:

```python
@classmethod
def from_index(cls, index_path: AnyPath, init_config: Dict[str, Any]) -> "PCPGenericExperiment":
    # Load index
    index = load_yaml(index_path)

    # Create experiment instance
    experiment = cls()

    # Add user-provided parameters
    experiment.nuclear_channel = init_config["nuclear_channel"]
    experiment.cell_channel = init_config["cell_channel"]
    experiment.mito_channel = init_config["mito_channel"]
    experiment.barcode_csv_path = init_config["barcode_csv_path"]
    experiment.image_overlap_percentage = init_config["image_overlap_percentage"]

    # Infer parameters from index
    experiment.dataset_id = index["dataset_id"]

    # Create dataframes for CP and SBS images
    experiment.cp_images_df = create_cp_images_dataframe(index)
    experiment.sbs_images_df = create_sbs_images_dataframe(index)

    # Calculate derived parameters
    experiment.images_per_well = calculate_images_per_well(experiment.cp_images_df)
    experiment.cp_channels = extract_cp_channels(experiment.cp_images_df)
    experiment.cp_channel_count = len(experiment.cp_channels)
    experiment.sbs_channels = extract_sbs_channels(experiment.sbs_images_df)
    experiment.sbs_channel_count = len(experiment.sbs_channels)

    # More parameter inference...

    return experiment
```

## Using Experiment Configurations

Once configured, the experiment object is passed to modules when creating them:

```python
# Create a module with experiment configuration
illum_calc_module = CPIllumCalcLoadDataModule.from_config(
    data_config=data_config,
    experiment=pcp_experiment
)
```

The module then uses the experiment configuration to set its parameters:

> "So here, if you look at like, from config function, right, we are using lot of data config things right for them, where to read data from, where to write data from, where to write data to. But we're also like, you know, using the experiment and looking at like, what the nuclei channel is, what the cell channel is, and they were using that to construct our command and the entire pipeline."

## Different Experiment Types

The architecture supports different experiment types:

> "In this, in this run, or in this notebook, we are doing PCP, generic. That's what then you might give it. But you can imagine calling it, you know, PCP, I don't know the saber or something faster, slow to color chemistry, you know, whatever variants you want, right?"

Each experiment type can have its own class with specific parameter inference logic.

## Creating New Experiment Types

To create a new experiment type:

1. Create a new file in the experiments folder
2. Define a class that inherits from ExperimentBase
3. Implement the from_index method
4. Define parameter inference logic
5. Register the experiment class in the registry

As explained in the transcript:

> "So you know, in future, if you want to extend this to different experiments. Here you do this, right? You create a new file, and then you create a new class and inherit from the experiment class, right? And the method you have to define is called from index."

## Experiment Registry

Experiments are registered in a registry to make them discoverable:

```python
from starrynight.experiments.registry import register_experiment

@register_experiment("pcp_generic")
class PCPGenericExperiment(ExperimentBase):
    """Experiment configuration for generic Plate Cell Painting."""
    # Implementation...
```

This allows experiments to be looked up by name.

## Benefits of Experiment Configuration

The experiment configuration approach offers several benefits:

1. **Reduced Manual Configuration** - Many parameters are inferred automatically
2. **Consistency** - Parameters are defined once and used consistently
3. **Validation** - Parameters can be validated during inference
4. **Extensibility** - New experiment types can be added without changing modules
5. **Separation of Concerns** - Experiment logic is separate from module logic

## Example: Complete Experiment Class

Here's a more complete example of an experiment class:

```python
@register_experiment("pcp_generic")
class PCPGenericExperiment(ExperimentBase):
    """
    Experiment configuration for generic Plate Cell Painting.
    """

    def __init__(self):
        """Initialize experiment configuration."""
        # User-provided parameters
        self.nuclear_channel = None
        self.cell_channel = None
        self.mito_channel = None
        self.barcode_csv_path = None
        self.image_overlap_percentage = None

        # Inferred parameters
        self.dataset_id = None
        self.cp_images_df = None
        self.sbs_images_df = None
        self.images_per_well = None
        self.cp_channels = None
        self.cp_channel_count = None
        self.sbs_channels = None
        self.sbs_channel_count = None
        # More parameters...

    @classmethod
    def from_index(cls, index_path: AnyPath, init_config: Dict[str, Any]) -> "PCPGenericExperiment":
        """Create experiment from index and initial config."""
        # Implementation...

        # Load index
        index = load_yaml(index_path)

        # Create experiment instance
        experiment = cls()

        # Set user-provided parameters
        experiment.nuclear_channel = init_config["nuclear_channel"]
        experiment.cell_channel = init_config["cell_channel"]
        experiment.mito_channel = init_config["mito_channel"]
        experiment.barcode_csv_path = init_config["barcode_csv_path"]
        experiment.image_overlap_percentage = init_config["image_overlap_percentage"]

        # Infer parameters from index
        # (implementation details...)

        return experiment

    def validate(self) -> bool:
        """Validate experiment configuration."""
        # Check required parameters
        if not self.nuclear_channel:
            raise ValueError("Nuclear channel must be specified")
        if not self.cell_channel:
            raise ValueError("Cell channel must be specified")

        # More validation...

        return True
```

## Serialization and Deserialization

Experiment configurations can be serialized and deserialized:

```python
# Serialize experiment to JSON
experiment_json = pcp_experiment.to_json()

# Save to file
with open("experiment_config.json", "w") as f:
    f.write(experiment_json)

# Later, load from file
with open("experiment_config.json", "r") as f:
    experiment_json = f.read()

# Deserialize experiment
pcp_experiment = PCPGenericExperiment.from_json(experiment_json)
```

This allows experiment configurations to be saved and restored.

## Conclusion

Experiment configuration in StarryNight provides a powerful mechanism for managing experiment-specific parameters, inferring settings from data, and configuring modules. By separating experiment-specific logic from module implementation, it enables flexibility, extensibility, and consistency across the pipeline system.

The experiment layer forms a critical bridge between user input and module configuration, reducing manual configuration burden while maintaining flexibility for different experiment types.
